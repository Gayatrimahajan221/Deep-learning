{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a regression dataset using scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import make_regression\n",
    "x,y  = make_regression(n_samples=3000, n_features= 30,\n",
    "                    n_informative = 28, noise=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.71827942, -0.07007371, -2.8807235 , ...,  0.55875312,\n",
       "        -0.87841759, -0.31143446],\n",
       "       [-0.12946552,  0.4509102 , -0.22386779, ...,  0.47038416,\n",
       "        -2.21539143,  1.3816385 ],\n",
       "       [ 0.24136957,  1.13337657,  0.07615875, ..., -0.92070334,\n",
       "         0.20400935,  0.85537708],\n",
       "       ...,\n",
       "       [ 1.56947425, -0.98543931, -0.68558038, ...,  0.19199239,\n",
       "         0.47005926,  0.50240498],\n",
       "       [ 0.696168  ,  1.64337816, -0.08809124, ...,  0.75109945,\n",
       "        -1.97548777, -2.06508305],\n",
       "       [ 0.17293044,  1.05127132, -0.55991632, ..., -0.04062406,\n",
       "        -0.44272303,  1.14910819]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -45.03468463, -253.02652499,  496.76697472, ...,  207.02333227,\n",
       "       -828.35114667,  -98.9642237 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting x and y to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x1',\n",
       " 'x2',\n",
       " 'x3',\n",
       " 'x4',\n",
       " 'x5',\n",
       " 'x6',\n",
       " 'x7',\n",
       " 'x8',\n",
       " 'x9',\n",
       " 'x10',\n",
       " 'x11',\n",
       " 'x12',\n",
       " 'x13',\n",
       " 'x14',\n",
       " 'x15',\n",
       " 'x16',\n",
       " 'x17',\n",
       " 'x18',\n",
       " 'x19',\n",
       " 'x20',\n",
       " 'x21',\n",
       " 'x22',\n",
       " 'x23',\n",
       " 'x24',\n",
       " 'x25',\n",
       " 'x26',\n",
       " 'x27',\n",
       " 'x28',\n",
       " 'x29',\n",
       " 'x30']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [f'x{i+1}' for i in range (30)]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.718279</td>\n",
       "      <td>-0.070074</td>\n",
       "      <td>-2.880723</td>\n",
       "      <td>-0.291797</td>\n",
       "      <td>-1.279408</td>\n",
       "      <td>0.360495</td>\n",
       "      <td>-2.030042</td>\n",
       "      <td>-0.426785</td>\n",
       "      <td>0.442853</td>\n",
       "      <td>0.112514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.379176</td>\n",
       "      <td>0.545999</td>\n",
       "      <td>-1.238762</td>\n",
       "      <td>0.210254</td>\n",
       "      <td>2.233469</td>\n",
       "      <td>0.501408</td>\n",
       "      <td>0.311878</td>\n",
       "      <td>0.558753</td>\n",
       "      <td>-0.878418</td>\n",
       "      <td>-0.311434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.129466</td>\n",
       "      <td>0.450910</td>\n",
       "      <td>-0.223868</td>\n",
       "      <td>-1.127200</td>\n",
       "      <td>-0.765647</td>\n",
       "      <td>-0.194988</td>\n",
       "      <td>-0.887412</td>\n",
       "      <td>0.706774</td>\n",
       "      <td>-0.341742</td>\n",
       "      <td>0.092110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767348</td>\n",
       "      <td>-1.111131</td>\n",
       "      <td>-1.120872</td>\n",
       "      <td>-0.434288</td>\n",
       "      <td>0.826882</td>\n",
       "      <td>-0.244658</td>\n",
       "      <td>0.296457</td>\n",
       "      <td>0.470384</td>\n",
       "      <td>-2.215391</td>\n",
       "      <td>1.381639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.241370</td>\n",
       "      <td>1.133377</td>\n",
       "      <td>0.076159</td>\n",
       "      <td>-0.597106</td>\n",
       "      <td>-0.569812</td>\n",
       "      <td>-1.097820</td>\n",
       "      <td>-0.405152</td>\n",
       "      <td>0.360265</td>\n",
       "      <td>0.296881</td>\n",
       "      <td>-0.184067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.519368</td>\n",
       "      <td>1.398581</td>\n",
       "      <td>1.022523</td>\n",
       "      <td>-0.081239</td>\n",
       "      <td>0.339850</td>\n",
       "      <td>1.128266</td>\n",
       "      <td>1.101489</td>\n",
       "      <td>-0.920703</td>\n",
       "      <td>0.204009</td>\n",
       "      <td>0.855377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.066140</td>\n",
       "      <td>1.154356</td>\n",
       "      <td>0.065168</td>\n",
       "      <td>0.251785</td>\n",
       "      <td>-0.178338</td>\n",
       "      <td>-1.304646</td>\n",
       "      <td>-1.776299</td>\n",
       "      <td>-1.545955</td>\n",
       "      <td>-1.463394</td>\n",
       "      <td>-0.137389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376657</td>\n",
       "      <td>1.021651</td>\n",
       "      <td>1.064456</td>\n",
       "      <td>-1.066433</td>\n",
       "      <td>-1.620960</td>\n",
       "      <td>1.388090</td>\n",
       "      <td>1.764874</td>\n",
       "      <td>-0.946784</td>\n",
       "      <td>-0.095042</td>\n",
       "      <td>1.812141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.630665</td>\n",
       "      <td>-1.333967</td>\n",
       "      <td>-0.606582</td>\n",
       "      <td>1.170996</td>\n",
       "      <td>1.342460</td>\n",
       "      <td>-1.284969</td>\n",
       "      <td>1.374057</td>\n",
       "      <td>-1.007511</td>\n",
       "      <td>-0.323503</td>\n",
       "      <td>0.265850</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500754</td>\n",
       "      <td>0.169756</td>\n",
       "      <td>0.967334</td>\n",
       "      <td>0.028729</td>\n",
       "      <td>0.757923</td>\n",
       "      <td>0.563454</td>\n",
       "      <td>0.625839</td>\n",
       "      <td>0.074512</td>\n",
       "      <td>-0.593699</td>\n",
       "      <td>-0.572639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0 -0.718279 -0.070074 -2.880723 -0.291797 -1.279408  0.360495 -2.030042   \n",
       "1 -0.129466  0.450910 -0.223868 -1.127200 -0.765647 -0.194988 -0.887412   \n",
       "2  0.241370  1.133377  0.076159 -0.597106 -0.569812 -1.097820 -0.405152   \n",
       "3 -0.066140  1.154356  0.065168  0.251785 -0.178338 -1.304646 -1.776299   \n",
       "4  0.630665 -1.333967 -0.606582  1.170996  1.342460 -1.284969  1.374057   \n",
       "\n",
       "         x8        x9       x10  ...       x21       x22       x23       x24  \\\n",
       "0 -0.426785  0.442853  0.112514  ... -1.379176  0.545999 -1.238762  0.210254   \n",
       "1  0.706774 -0.341742  0.092110  ...  0.767348 -1.111131 -1.120872 -0.434288   \n",
       "2  0.360265  0.296881 -0.184067  ... -0.519368  1.398581  1.022523 -0.081239   \n",
       "3 -1.545955 -1.463394 -0.137389  ...  0.376657  1.021651  1.064456 -1.066433   \n",
       "4 -1.007511 -0.323503  0.265850  ... -0.500754  0.169756  0.967334  0.028729   \n",
       "\n",
       "        x25       x26       x27       x28       x29       x30  \n",
       "0  2.233469  0.501408  0.311878  0.558753 -0.878418 -0.311434  \n",
       "1  0.826882 -0.244658  0.296457  0.470384 -2.215391  1.381639  \n",
       "2  0.339850  1.128266  1.101489 -0.920703  0.204009  0.855377  \n",
       "3 -1.620960  1.388090  1.764874 -0.946784 -0.095042  1.812141  \n",
       "4  0.757923  0.563454  0.625839  0.074512 -0.593699 -0.572639  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "x = pd.DataFrame(x, columns = cols)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.034685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-253.026525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>496.766975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.601647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>236.457790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            y\n",
       "0  -45.034685\n",
       "1 -253.026525\n",
       "2  496.766975\n",
       "3   -4.601647\n",
       "4  236.457790"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(y, columns=['y'])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a scikit learn pipeline for x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline(steps=[('impute', SimpleImputer(strategy='mean')),\n",
    "                           ('scaler' , StandardScaler())]).set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.688919</td>\n",
       "      <td>-0.057155</td>\n",
       "      <td>-2.863120</td>\n",
       "      <td>-0.305510</td>\n",
       "      <td>-1.275101</td>\n",
       "      <td>0.352911</td>\n",
       "      <td>-1.974449</td>\n",
       "      <td>-0.412523</td>\n",
       "      <td>0.431024</td>\n",
       "      <td>0.109518</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.402585</td>\n",
       "      <td>0.574088</td>\n",
       "      <td>-1.226719</td>\n",
       "      <td>0.191083</td>\n",
       "      <td>2.186029</td>\n",
       "      <td>0.475576</td>\n",
       "      <td>0.347794</td>\n",
       "      <td>0.578474</td>\n",
       "      <td>-0.918601</td>\n",
       "      <td>-0.325387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.105807</td>\n",
       "      <td>0.470406</td>\n",
       "      <td>-0.205413</td>\n",
       "      <td>-1.147154</td>\n",
       "      <td>-0.763248</td>\n",
       "      <td>-0.201377</td>\n",
       "      <td>-0.849465</td>\n",
       "      <td>0.716442</td>\n",
       "      <td>-0.367298</td>\n",
       "      <td>0.090012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772182</td>\n",
       "      <td>-1.104212</td>\n",
       "      <td>-1.110130</td>\n",
       "      <td>-0.448803</td>\n",
       "      <td>0.802196</td>\n",
       "      <td>-0.276927</td>\n",
       "      <td>0.332451</td>\n",
       "      <td>0.489438</td>\n",
       "      <td>-2.268167</td>\n",
       "      <td>1.395733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.261436</td>\n",
       "      <td>1.161488</td>\n",
       "      <td>0.094710</td>\n",
       "      <td>-0.613100</td>\n",
       "      <td>-0.568141</td>\n",
       "      <td>-1.102267</td>\n",
       "      <td>-0.374652</td>\n",
       "      <td>0.371337</td>\n",
       "      <td>0.282499</td>\n",
       "      <td>-0.174010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.531464</td>\n",
       "      <td>1.437562</td>\n",
       "      <td>1.009621</td>\n",
       "      <td>-0.098304</td>\n",
       "      <td>0.323041</td>\n",
       "      <td>1.107841</td>\n",
       "      <td>1.133389</td>\n",
       "      <td>-0.912149</td>\n",
       "      <td>0.174020</td>\n",
       "      <td>0.860754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.043094</td>\n",
       "      <td>1.182733</td>\n",
       "      <td>0.083716</td>\n",
       "      <td>0.242134</td>\n",
       "      <td>-0.178121</td>\n",
       "      <td>-1.308648</td>\n",
       "      <td>-1.724625</td>\n",
       "      <td>-1.527157</td>\n",
       "      <td>-1.508573</td>\n",
       "      <td>-0.129386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376350</td>\n",
       "      <td>1.055817</td>\n",
       "      <td>1.051092</td>\n",
       "      <td>-1.076381</td>\n",
       "      <td>-1.606051</td>\n",
       "      <td>1.369906</td>\n",
       "      <td>1.793399</td>\n",
       "      <td>-0.938426</td>\n",
       "      <td>-0.127848</td>\n",
       "      <td>1.833367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.646962</td>\n",
       "      <td>-1.337003</td>\n",
       "      <td>-0.588250</td>\n",
       "      <td>1.168212</td>\n",
       "      <td>1.337030</td>\n",
       "      <td>-1.289013</td>\n",
       "      <td>1.377081</td>\n",
       "      <td>-0.990895</td>\n",
       "      <td>-0.348739</td>\n",
       "      <td>0.256105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.512606</td>\n",
       "      <td>0.193039</td>\n",
       "      <td>0.955041</td>\n",
       "      <td>0.010869</td>\n",
       "      <td>0.734352</td>\n",
       "      <td>0.538156</td>\n",
       "      <td>0.660157</td>\n",
       "      <td>0.090578</td>\n",
       "      <td>-0.631202</td>\n",
       "      <td>-0.590918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0 -0.688919 -0.057155 -2.863120 -0.305510 -1.275101  0.352911 -1.974449   \n",
       "1 -0.105807  0.470406 -0.205413 -1.147154 -0.763248 -0.201377 -0.849465   \n",
       "2  0.261436  1.161488  0.094710 -0.613100 -0.568141 -1.102267 -0.374652   \n",
       "3 -0.043094  1.182733  0.083716  0.242134 -0.178121 -1.308648 -1.724625   \n",
       "4  0.646962 -1.337003 -0.588250  1.168212  1.337030 -1.289013  1.377081   \n",
       "\n",
       "         x8        x9       x10  ...       x21       x22       x23       x24  \\\n",
       "0 -0.412523  0.431024  0.109518  ... -1.402585  0.574088 -1.226719  0.191083   \n",
       "1  0.716442 -0.367298  0.090012  ...  0.772182 -1.104212 -1.110130 -0.448803   \n",
       "2  0.371337  0.282499 -0.174010  ... -0.531464  1.437562  1.009621 -0.098304   \n",
       "3 -1.527157 -1.508573 -0.129386  ...  0.376350  1.055817  1.051092 -1.076381   \n",
       "4 -0.990895 -0.348739  0.256105  ... -0.512606  0.193039  0.955041  0.010869   \n",
       "\n",
       "        x25       x26       x27       x28       x29       x30  \n",
       "0  2.186029  0.475576  0.347794  0.578474 -0.918601 -0.325387  \n",
       "1  0.802196 -0.276927  0.332451  0.489438 -2.268167  1.395733  \n",
       "2  0.323041  1.107841  1.133389 -0.912149  0.174020  0.860754  \n",
       "3 -1.606051  1.369906  1.793399 -0.938426 -0.127848  1.833367  \n",
       "4  0.734352  0.538156  0.660157  0.090578 -0.631202 -0.590918  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pre = num_pipe.fit_transform(x)\n",
    "x_pre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applay train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_pre, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>0.052039</td>\n",
       "      <td>-0.940475</td>\n",
       "      <td>-0.943021</td>\n",
       "      <td>-0.987331</td>\n",
       "      <td>1.090220</td>\n",
       "      <td>1.585467</td>\n",
       "      <td>-0.678379</td>\n",
       "      <td>-1.139013</td>\n",
       "      <td>-0.171146</td>\n",
       "      <td>-1.170170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922744</td>\n",
       "      <td>0.526633</td>\n",
       "      <td>0.016138</td>\n",
       "      <td>0.607965</td>\n",
       "      <td>0.333314</td>\n",
       "      <td>-1.520318</td>\n",
       "      <td>0.257526</td>\n",
       "      <td>-0.046280</td>\n",
       "      <td>0.278598</td>\n",
       "      <td>0.122691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1.253791</td>\n",
       "      <td>-0.710742</td>\n",
       "      <td>-1.791321</td>\n",
       "      <td>1.539163</td>\n",
       "      <td>-1.114221</td>\n",
       "      <td>1.012629</td>\n",
       "      <td>0.244713</td>\n",
       "      <td>-1.926104</td>\n",
       "      <td>-0.445870</td>\n",
       "      <td>-0.629977</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.077994</td>\n",
       "      <td>-0.744548</td>\n",
       "      <td>-1.040224</td>\n",
       "      <td>0.435301</td>\n",
       "      <td>-0.454281</td>\n",
       "      <td>1.101016</td>\n",
       "      <td>-0.416873</td>\n",
       "      <td>-0.970135</td>\n",
       "      <td>-0.663722</td>\n",
       "      <td>0.115474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>0.252961</td>\n",
       "      <td>-0.020081</td>\n",
       "      <td>-0.787437</td>\n",
       "      <td>1.481952</td>\n",
       "      <td>-0.891972</td>\n",
       "      <td>0.763080</td>\n",
       "      <td>0.103481</td>\n",
       "      <td>-0.422697</td>\n",
       "      <td>-0.032422</td>\n",
       "      <td>-0.897198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213005</td>\n",
       "      <td>-0.275669</td>\n",
       "      <td>0.743194</td>\n",
       "      <td>-0.255197</td>\n",
       "      <td>-0.662567</td>\n",
       "      <td>-0.740384</td>\n",
       "      <td>1.096108</td>\n",
       "      <td>2.044021</td>\n",
       "      <td>-1.143672</td>\n",
       "      <td>0.657581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0.522782</td>\n",
       "      <td>-0.644630</td>\n",
       "      <td>-0.164250</td>\n",
       "      <td>-0.473433</td>\n",
       "      <td>1.297058</td>\n",
       "      <td>1.305110</td>\n",
       "      <td>0.098092</td>\n",
       "      <td>-0.510435</td>\n",
       "      <td>1.836239</td>\n",
       "      <td>0.641412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.738259</td>\n",
       "      <td>1.205840</td>\n",
       "      <td>1.346459</td>\n",
       "      <td>0.796726</td>\n",
       "      <td>1.464666</td>\n",
       "      <td>1.285444</td>\n",
       "      <td>-0.318203</td>\n",
       "      <td>1.055037</td>\n",
       "      <td>1.077651</td>\n",
       "      <td>-0.034905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>-0.257471</td>\n",
       "      <td>0.131504</td>\n",
       "      <td>-0.411423</td>\n",
       "      <td>0.237039</td>\n",
       "      <td>1.631228</td>\n",
       "      <td>1.070852</td>\n",
       "      <td>-1.716534</td>\n",
       "      <td>-1.038329</td>\n",
       "      <td>0.608915</td>\n",
       "      <td>0.980584</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.106273</td>\n",
       "      <td>-0.672314</td>\n",
       "      <td>-0.409232</td>\n",
       "      <td>-0.574227</td>\n",
       "      <td>-0.049304</td>\n",
       "      <td>-1.098888</td>\n",
       "      <td>0.582422</td>\n",
       "      <td>-1.028832</td>\n",
       "      <td>1.017513</td>\n",
       "      <td>1.018863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x1        x2        x3        x4        x5        x6        x7  \\\n",
       "1643  0.052039 -0.940475 -0.943021 -0.987331  1.090220  1.585467 -0.678379   \n",
       "137   1.253791 -0.710742 -1.791321  1.539163 -1.114221  1.012629  0.244713   \n",
       "1205  0.252961 -0.020081 -0.787437  1.481952 -0.891972  0.763080  0.103481   \n",
       "523   0.522782 -0.644630 -0.164250 -0.473433  1.297058  1.305110  0.098092   \n",
       "1493 -0.257471  0.131504 -0.411423  0.237039  1.631228  1.070852 -1.716534   \n",
       "\n",
       "            x8        x9       x10  ...       x21       x22       x23  \\\n",
       "1643 -1.139013 -0.171146 -1.170170  ...  0.922744  0.526633  0.016138   \n",
       "137  -1.926104 -0.445870 -0.629977  ... -1.077994 -0.744548 -1.040224   \n",
       "1205 -0.422697 -0.032422 -0.897198  ... -0.213005 -0.275669  0.743194   \n",
       "523  -0.510435  1.836239  0.641412  ... -0.738259  1.205840  1.346459   \n",
       "1493 -1.038329  0.608915  0.980584  ... -1.106273 -0.672314 -0.409232   \n",
       "\n",
       "           x24       x25       x26       x27       x28       x29       x30  \n",
       "1643  0.607965  0.333314 -1.520318  0.257526 -0.046280  0.278598  0.122691  \n",
       "137   0.435301 -0.454281  1.101016 -0.416873 -0.970135 -0.663722  0.115474  \n",
       "1205 -0.255197 -0.662567 -0.740384  1.096108  2.044021 -1.143672  0.657581  \n",
       "523   0.796726  1.464666  1.285444 -0.318203  1.055037  1.077651 -0.034905  \n",
       "1493 -0.574227 -0.049304 -1.098888  0.582422 -1.028832  1.017513  1.018863  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>112.433915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>-1083.527732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>-128.674183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>761.187440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>-172.902429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                y\n",
       "1643   112.433915\n",
       "137  -1083.527732\n",
       "1205  -128.674183\n",
       "523    761.187440\n",
       "1493  -172.902429"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>-0.169150</td>\n",
       "      <td>0.409952</td>\n",
       "      <td>1.307803</td>\n",
       "      <td>0.700982</td>\n",
       "      <td>-0.022220</td>\n",
       "      <td>-0.114715</td>\n",
       "      <td>-0.166075</td>\n",
       "      <td>1.478153</td>\n",
       "      <td>-0.395357</td>\n",
       "      <td>-0.013553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833916</td>\n",
       "      <td>1.384411</td>\n",
       "      <td>0.676108</td>\n",
       "      <td>-0.296128</td>\n",
       "      <td>-0.309297</td>\n",
       "      <td>0.556642</td>\n",
       "      <td>0.432878</td>\n",
       "      <td>-0.163328</td>\n",
       "      <td>-1.799377</td>\n",
       "      <td>0.075014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>0.637073</td>\n",
       "      <td>-1.927265</td>\n",
       "      <td>1.005873</td>\n",
       "      <td>0.295788</td>\n",
       "      <td>-1.197994</td>\n",
       "      <td>1.168578</td>\n",
       "      <td>-0.009949</td>\n",
       "      <td>-1.740025</td>\n",
       "      <td>-0.893787</td>\n",
       "      <td>-1.032446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375229</td>\n",
       "      <td>0.321581</td>\n",
       "      <td>1.098016</td>\n",
       "      <td>-2.367612</td>\n",
       "      <td>-2.161798</td>\n",
       "      <td>0.942354</td>\n",
       "      <td>0.164110</td>\n",
       "      <td>-0.625070</td>\n",
       "      <td>1.951268</td>\n",
       "      <td>-0.588490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>1.505908</td>\n",
       "      <td>0.342662</td>\n",
       "      <td>1.049776</td>\n",
       "      <td>0.563217</td>\n",
       "      <td>1.272666</td>\n",
       "      <td>0.319483</td>\n",
       "      <td>-0.145469</td>\n",
       "      <td>0.724367</td>\n",
       "      <td>-0.875059</td>\n",
       "      <td>1.157968</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.361983</td>\n",
       "      <td>-0.488970</td>\n",
       "      <td>1.633057</td>\n",
       "      <td>-0.719981</td>\n",
       "      <td>-0.043802</td>\n",
       "      <td>0.555418</td>\n",
       "      <td>1.668127</td>\n",
       "      <td>1.919041</td>\n",
       "      <td>-0.105455</td>\n",
       "      <td>0.233323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>0.700346</td>\n",
       "      <td>2.323657</td>\n",
       "      <td>-0.405742</td>\n",
       "      <td>-0.849900</td>\n",
       "      <td>0.199404</td>\n",
       "      <td>-0.194465</td>\n",
       "      <td>-0.126883</td>\n",
       "      <td>-0.110462</td>\n",
       "      <td>2.882282</td>\n",
       "      <td>0.295011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.451245</td>\n",
       "      <td>0.431099</td>\n",
       "      <td>-0.411627</td>\n",
       "      <td>0.764152</td>\n",
       "      <td>1.172289</td>\n",
       "      <td>-0.002425</td>\n",
       "      <td>-0.254325</td>\n",
       "      <td>-2.008459</td>\n",
       "      <td>0.353949</td>\n",
       "      <td>0.749569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>0.222637</td>\n",
       "      <td>0.279963</td>\n",
       "      <td>-1.257113</td>\n",
       "      <td>0.583550</td>\n",
       "      <td>-0.564966</td>\n",
       "      <td>-1.512064</td>\n",
       "      <td>0.678992</td>\n",
       "      <td>-2.255414</td>\n",
       "      <td>1.393263</td>\n",
       "      <td>0.905597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.992292</td>\n",
       "      <td>-0.802682</td>\n",
       "      <td>0.288486</td>\n",
       "      <td>-0.037195</td>\n",
       "      <td>-0.669431</td>\n",
       "      <td>0.305328</td>\n",
       "      <td>-1.311686</td>\n",
       "      <td>-1.082929</td>\n",
       "      <td>1.749682</td>\n",
       "      <td>-1.388976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x1        x2        x3        x4        x5        x6        x7  \\\n",
       "465  -0.169150  0.409952  1.307803  0.700982 -0.022220 -0.114715 -0.166075   \n",
       "904   0.637073 -1.927265  1.005873  0.295788 -1.197994  1.168578 -0.009949   \n",
       "2639  1.505908  0.342662  1.049776  0.563217  1.272666  0.319483 -0.145469   \n",
       "2125  0.700346  2.323657 -0.405742 -0.849900  0.199404 -0.194465 -0.126883   \n",
       "1962  0.222637  0.279963 -1.257113  0.583550 -0.564966 -1.512064  0.678992   \n",
       "\n",
       "            x8        x9       x10  ...       x21       x22       x23  \\\n",
       "465   1.478153 -0.395357 -0.013553  ... -0.833916  1.384411  0.676108   \n",
       "904  -1.740025 -0.893787 -1.032446  ...  0.375229  0.321581  1.098016   \n",
       "2639  0.724367 -0.875059  1.157968  ... -0.361983 -0.488970  1.633057   \n",
       "2125 -0.110462  2.882282  0.295011  ... -0.451245  0.431099 -0.411627   \n",
       "1962 -2.255414  1.393263  0.905597  ... -0.992292 -0.802682  0.288486   \n",
       "\n",
       "           x24       x25       x26       x27       x28       x29       x30  \n",
       "465  -0.296128 -0.309297  0.556642  0.432878 -0.163328 -1.799377  0.075014  \n",
       "904  -2.367612 -2.161798  0.942354  0.164110 -0.625070  1.951268 -0.588490  \n",
       "2639 -0.719981 -0.043802  0.555418  1.668127  1.919041 -0.105455  0.233323  \n",
       "2125  0.764152  1.172289 -0.002425 -0.254325 -2.008459  0.353949  0.749569  \n",
       "1962 -0.037195 -0.669431  0.305328 -1.311686 -1.082929  1.749682 -1.388976  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>-153.360317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>-827.315745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>715.436126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>528.030227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>-44.600383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               y\n",
       "465  -153.360317\n",
       "904  -827.315745\n",
       "2639  715.436126\n",
       "2125  528.030227\n",
       "1962  -44.600383"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Deep Learning\\repository\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Deep Learning\\repository\\venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the neural network\n",
    "model = Sequential()\n",
    "\n",
    "# Create hidden layer 1\n",
    "model.add(Dense(units=64, activation='relu', input_shape=(xtrain.shape[1],)))\n",
    "# Create 2nd hidden layer with 32\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "# Create a output layer\n",
    "model.add(Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compiling he model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Deep Learning\\repository\\venv\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From d:\\Deep Learning\\repository\\venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Deep Learning\\repository\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "60/60 [==============================] - 2s 9ms/step - loss: 112383.5547 - mae: 265.4701 - val_loss: 115240.3516 - val_mae: 271.2670\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 108895.9844 - mae: 261.1650 - val_loss: 108299.8203 - val_mae: 262.6935\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 95557.9844 - mae: 243.7021 - val_loss: 88063.3516 - val_mae: 235.2506\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 67477.7344 - mae: 199.9977 - val_loss: 54240.2383 - val_mae: 178.3790\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 34495.5391 - mae: 133.4907 - val_loss: 24461.3359 - val_mae: 107.7317\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 13384.0850 - mae: 74.1105 - val_loss: 8561.3066 - val_mae: 58.3165\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 4395.6895 - mae: 42.4162 - val_loss: 2848.0845 - val_mae: 35.9002\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 1923.8451 - mae: 31.6779 - val_loss: 1606.3770 - val_mae: 29.2316\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 1327.1003 - mae: 27.8461 - val_loss: 1155.3922 - val_mae: 25.8875\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 1005.0831 - mae: 24.5428 - val_loss: 867.8835 - val_mae: 22.4583\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 757.0775 - mae: 21.2829 - val_loss: 672.3188 - val_mae: 19.7950\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 637.9916 - mae: 19.6250 - val_loss: 594.8390 - val_mae: 19.1422\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 594.8475 - mae: 19.1550 - val_loss: 561.6788 - val_mae: 18.7629\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 562.4247 - mae: 18.6955 - val_loss: 551.1251 - val_mae: 17.9913\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 540.4510 - mae: 18.2533 - val_loss: 522.7150 - val_mae: 17.6989\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 515.9737 - mae: 17.9836 - val_loss: 513.9555 - val_mae: 17.9978\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 496.6678 - mae: 17.6306 - val_loss: 484.5729 - val_mae: 17.2143\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 472.3419 - mae: 17.0617 - val_loss: 470.5453 - val_mae: 17.1789\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 455.9058 - mae: 16.8606 - val_loss: 452.5186 - val_mae: 16.5783\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 433.4048 - mae: 16.3535 - val_loss: 430.3695 - val_mae: 16.3470\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 415.1743 - mae: 16.0578 - val_loss: 417.8725 - val_mae: 15.8730\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 394.4590 - mae: 15.7183 - val_loss: 413.6862 - val_mae: 15.5287\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 377.4494 - mae: 15.1991 - val_loss: 384.5989 - val_mae: 15.5261\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 362.4477 - mae: 15.0098 - val_loss: 373.9669 - val_mae: 15.2300\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 344.4742 - mae: 14.6330 - val_loss: 356.9616 - val_mae: 14.6565\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 324.9718 - mae: 14.2601 - val_loss: 341.7242 - val_mae: 14.6366\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 310.2508 - mae: 13.9045 - val_loss: 327.7705 - val_mae: 14.3504\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 295.5656 - mae: 13.6093 - val_loss: 320.1869 - val_mae: 14.0923\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 285.5623 - mae: 13.2619 - val_loss: 305.1132 - val_mae: 13.8769\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 268.0118 - mae: 12.8716 - val_loss: 292.9452 - val_mae: 13.5867\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 256.1105 - mae: 12.6588 - val_loss: 278.9648 - val_mae: 13.2608\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 240.3304 - mae: 12.2742 - val_loss: 273.3126 - val_mae: 13.0488\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 231.5706 - mae: 12.0146 - val_loss: 258.2835 - val_mae: 12.7454\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 219.6477 - mae: 11.7042 - val_loss: 253.7661 - val_mae: 12.5841\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 208.6420 - mae: 11.4683 - val_loss: 241.3932 - val_mae: 12.2937\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 197.8876 - mae: 11.1389 - val_loss: 230.3399 - val_mae: 12.0514\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 188.1005 - mae: 10.8666 - val_loss: 222.8974 - val_mae: 11.9015\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 180.0193 - mae: 10.6712 - val_loss: 218.7999 - val_mae: 11.6994\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 170.0837 - mae: 10.3592 - val_loss: 213.3271 - val_mae: 11.6089\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 166.5989 - mae: 10.2593 - val_loss: 203.1898 - val_mae: 11.3114\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 157.6431 - mae: 9.9629 - val_loss: 196.5776 - val_mae: 11.1345\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 152.0865 - mae: 9.8099 - val_loss: 193.7281 - val_mae: 11.0431\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 144.2911 - mae: 9.5615 - val_loss: 187.7852 - val_mae: 10.8548\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 139.5746 - mae: 9.4314 - val_loss: 183.0595 - val_mae: 10.7318\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 134.5840 - mae: 9.2520 - val_loss: 181.9259 - val_mae: 10.6568\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 128.0545 - mae: 9.0111 - val_loss: 178.3394 - val_mae: 10.5287\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 124.9314 - mae: 8.9017 - val_loss: 171.3191 - val_mae: 10.3370\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 119.6109 - mae: 8.7054 - val_loss: 174.3992 - val_mae: 10.4106\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 116.9039 - mae: 8.6105 - val_loss: 167.0524 - val_mae: 10.2091\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 112.8102 - mae: 8.4806 - val_loss: 164.6780 - val_mae: 10.1291\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 110.4083 - mae: 8.3844 - val_loss: 161.5025 - val_mae: 10.0378\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 107.1095 - mae: 8.2778 - val_loss: 160.5921 - val_mae: 10.0026\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 105.8096 - mae: 8.1909 - val_loss: 159.0018 - val_mae: 9.9769\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 100.9730 - mae: 7.9809 - val_loss: 157.2429 - val_mae: 9.9030\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 100.4106 - mae: 8.0138 - val_loss: 155.7353 - val_mae: 9.8579\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 96.5231 - mae: 7.8255 - val_loss: 153.2808 - val_mae: 9.7370\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 95.7598 - mae: 7.7652 - val_loss: 150.6570 - val_mae: 9.7237\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 94.6216 - mae: 7.7262 - val_loss: 152.7208 - val_mae: 9.7670\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 91.3515 - mae: 7.5832 - val_loss: 149.4281 - val_mae: 9.5840\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 90.0424 - mae: 7.5385 - val_loss: 150.3594 - val_mae: 9.6571\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 88.1917 - mae: 7.4641 - val_loss: 147.2124 - val_mae: 9.5738\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 87.1550 - mae: 7.4082 - val_loss: 149.0834 - val_mae: 9.6196\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 86.7831 - mae: 7.3713 - val_loss: 146.1818 - val_mae: 9.4837\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 85.9180 - mae: 7.3130 - val_loss: 146.9836 - val_mae: 9.6160\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 85.1586 - mae: 7.2976 - val_loss: 152.2014 - val_mae: 9.6722\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 82.3462 - mae: 7.1916 - val_loss: 146.4675 - val_mae: 9.5295\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 81.8017 - mae: 7.0958 - val_loss: 147.1454 - val_mae: 9.5194\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 81.6343 - mae: 7.1173 - val_loss: 147.4469 - val_mae: 9.5212\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 80.5845 - mae: 7.0626 - val_loss: 150.5894 - val_mae: 9.6599\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 79.0015 - mae: 6.9971 - val_loss: 146.1349 - val_mae: 9.4814\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 77.6696 - mae: 6.9088 - val_loss: 147.5688 - val_mae: 9.5992\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 76.7240 - mae: 6.8713 - val_loss: 144.3038 - val_mae: 9.4435\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 76.5288 - mae: 6.8682 - val_loss: 144.4715 - val_mae: 9.4583\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 75.2071 - mae: 6.7965 - val_loss: 145.7169 - val_mae: 9.4948\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 75.0549 - mae: 6.7990 - val_loss: 143.7654 - val_mae: 9.4227\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 75.6029 - mae: 6.7990 - val_loss: 146.5286 - val_mae: 9.5222\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 73.0689 - mae: 6.7266 - val_loss: 149.0831 - val_mae: 9.6015\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 73.9931 - mae: 6.7577 - val_loss: 143.2203 - val_mae: 9.4244\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 73.8162 - mae: 6.7124 - val_loss: 141.0895 - val_mae: 9.3265\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 72.6683 - mae: 6.6215 - val_loss: 143.3184 - val_mae: 9.3855\n",
      "Epoch 81/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 69.0410 - mae: 6.5317 - val_loss: 146.2505 - val_mae: 9.5023\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 70.5684 - mae: 6.5457 - val_loss: 144.4376 - val_mae: 9.4742\n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 70.5841 - mae: 6.5574 - val_loss: 143.9433 - val_mae: 9.4432\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 69.0332 - mae: 6.5044 - val_loss: 144.4715 - val_mae: 9.4596\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 68.4756 - mae: 6.4556 - val_loss: 143.3618 - val_mae: 9.3685\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 70.0929 - mae: 6.5266 - val_loss: 139.4214 - val_mae: 9.2783\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 67.6783 - mae: 6.4087 - val_loss: 144.0379 - val_mae: 9.4244\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 66.8559 - mae: 6.3506 - val_loss: 148.4799 - val_mae: 9.5816\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 66.0863 - mae: 6.3501 - val_loss: 142.3515 - val_mae: 9.3891\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 66.1954 - mae: 6.3250 - val_loss: 140.0977 - val_mae: 9.2631\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 65.1221 - mae: 6.2582 - val_loss: 142.0960 - val_mae: 9.3400\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 64.0254 - mae: 6.2062 - val_loss: 146.5186 - val_mae: 9.4900\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 64.8638 - mae: 6.2800 - val_loss: 141.9521 - val_mae: 9.3673\n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 63.9088 - mae: 6.2344 - val_loss: 144.3299 - val_mae: 9.4307\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 62.6454 - mae: 6.1121 - val_loss: 141.7635 - val_mae: 9.3152\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 64.6063 - mae: 6.2205 - val_loss: 136.9891 - val_mae: 9.1600\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 62.4649 - mae: 6.1200 - val_loss: 150.6440 - val_mae: 9.7107\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 61.6220 - mae: 6.1060 - val_loss: 144.3890 - val_mae: 9.4231\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 60.9233 - mae: 6.0863 - val_loss: 145.5166 - val_mae: 9.4876\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 61.7137 - mae: 6.0532 - val_loss: 144.7706 - val_mae: 9.4133\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hist = model.fit(xtrain, ytrain, validation_split=0.2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(hist.history['loss'], label= \"Training loss\")\n",
    "plt.plot(hist.history['val_loss'],label='training loss')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"mean squared error\")\n",
    "plt.title('learning curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 2ms/step - loss: 75.5085 - mae: 6.6146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[75.508544921875, 6.614617347717285]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 1ms/step - loss: 159.7368 - mae: 10.1169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[159.73678588867188, 10.116900444030762]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting values for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred_tr = model.predict(xtrain)\n",
    "ypred_ts = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  115.3494 ],\n",
       "       [-1058.7048 ],\n",
       "       [ -123.81051],\n",
       "       [  762.7498 ],\n",
       "       [ -181.44531]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred_tr[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>112.433915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>-1083.527732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>-128.674183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>761.187440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>-172.902429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                y\n",
       "1643   112.433915\n",
       "137  -1083.527732\n",
       "1205  -128.674183\n",
       "523    761.187440\n",
       "1493  -172.902429"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-159.53928 ],\n",
       "       [-829.4342  ],\n",
       "       [ 718.1965  ],\n",
       "       [ 513.326   ],\n",
       "       [ -55.194218]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred_ts[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>-153.360317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>-827.315745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>715.436126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>528.030227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>-44.600383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               y\n",
       "465  -153.360317\n",
       "904  -827.315745\n",
       "2639  715.436126\n",
       "2125  528.030227\n",
       "1962  -44.600383"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating r2 score in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993347348384386"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_r2 = r2_score(ytrain, ypred_tr)\n",
    "tr_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9986569497837432"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_r2 = r2_score(ytest, ypred_ts)\n",
    "ts_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving the neural network model for given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                1984      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4097 (16.00 KB)\n",
      "Trainable params: 4097 (16.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Regression.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                1984      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4097 (16.00 KB)\n",
      "Trainable params: 4097 (16.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "nn = load_model('Regression.keras')\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
